{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Dependencies"
      ],
      "metadata": {
        "id": "xL4x0qRYPsKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import datetime\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import zipfile\n",
        "\n",
        "from collections import OrderedDict\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import average_precision_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "x6mS024WJqkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline"
      ],
      "metadata": {
        "id": "AJN0vZzwJ1Hj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import from Drive"
      ],
      "metadata": {
        "id": "xEZgGajrO7a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "IMAGES_ZIP_PATH = '/content/drive/MyDrive/CS2952Q-FP/MLRSNet/images.zip'\n",
        "LABELS_ZIP_PATH = '/content/drive/MyDrive/CS2952Q-FP/MLRSNet/labels.zip'\n",
        "LOCAL_IMAGES_DIR = '/content/images'\n",
        "LOCAL_LABELS_DIR = '/content/labels'\n",
        "\n",
        "def make_local_dir(dirname, zip_path):\n",
        "    os.makedirs(dirname, exist_ok=True)\n",
        "\n",
        "    if not os.listdir(dirname):\n",
        "        print(f'Unzipping {zip_path}...')\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
        "            zipf.extractall(dirname)\n",
        "        print(f'Completed unzipping {zip_path}.')\n",
        "    else:\n",
        "        print(f'{zip_path} was already unzipped.')\n",
        "\n",
        "    for subfolder in os.listdir(dirname):\n",
        "        subfolder_path = os.path.join(dirname, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            for f in os.listdir(subfolder_path):\n",
        "                src_path = os.path.join(subfolder_path, f)\n",
        "                dst_path = os.path.join(dirname, f)\n",
        "                shutil.move(src_path, dst_path)\n",
        "            os.rmdir(subfolder_path)\n",
        "\n",
        "make_local_dir(LOCAL_IMAGES_DIR, IMAGES_ZIP_PATH)\n",
        "make_local_dir(LOCAL_LABELS_DIR, LABELS_ZIP_PATH)"
      ],
      "metadata": {
        "id": "g2RVoLug0GLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation"
      ],
      "metadata": {
        "id": "Yf5QsklaPFL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def encode_labels() -> tuple[pd.DataFrame, int]:\n",
        "    # Read all label CSV files and combine them into a single DataFrame\n",
        "    label_files = glob.glob(os.path.join(LOCAL_LABELS_DIR, '*.csv'))\n",
        "\n",
        "    dfs = []\n",
        "    for label_file in label_files:\n",
        "        df = pd.read_csv(label_file)\n",
        "        dfs.append(df)\n",
        "    labels_df = pd.concat(dfs, ignore_index=True)\n",
        "    print(\"Columns in labels_df:\", labels_df.columns.tolist())\n",
        "\n",
        "    # Remove duplicate entries\n",
        "    labels_df = labels_df.drop_duplicates(subset='image')\n",
        "\n",
        "    # Correct typos in class names\n",
        "    labels_df = labels_df.rename(columns={\n",
        "        'habor': 'harbor',\n",
        "        'swimmimg pool': 'swimming pool'\n",
        "    })\n",
        "\n",
        "    # Get the list of all class names from the header of the CSV files\n",
        "    class_names = labels_df.columns.tolist()\n",
        "    class_names.remove('image')  # Remove 'image' column\n",
        "    num_classes = len(class_names)\n",
        "    class_to_index = {cls_name: idx for idx, cls_name in enumerate(class_names)}\n",
        "\n",
        "    # Map image filenames to their labels\n",
        "    labels_df['multi_hot'] = labels_df[class_names].values.tolist()\n",
        "\n",
        "    # Drop the individual class label columns to reduce redundancy\n",
        "    labels_df = labels_df.drop(columns=class_names)\n",
        "\n",
        "    # Pre-index all image paths\n",
        "    all_image_paths = glob.glob(os.path.join(LOCAL_IMAGES_DIR,'*.jpg'))\n",
        "    image_name_to_path = {}\n",
        "    for img_path in all_image_paths:\n",
        "        image_name = os.path.basename(img_path)\n",
        "        image_name_to_path[image_name] = img_path\n",
        "\n",
        "    # Build a mapping from image paths to multi-hot labels\n",
        "    data = {'image_path': [], 'multi_labels': []}\n",
        "\n",
        "    for idx, row in labels_df.iterrows():\n",
        "        image_name = row['image']\n",
        "        # Look up the image path directly\n",
        "        image_path = image_name_to_path.get(image_name)\n",
        "        if image_path is None:\n",
        "            print(f'Image {image_name} not found in dataset.')\n",
        "            continue\n",
        "        data['image_path'].append(image_path)\n",
        "        # Use the 'multi_hot' column directly\n",
        "        multi_hot = np.array(row['multi_hot'], dtype=np.float32)\n",
        "        data['multi_labels'].append(multi_hot)\n",
        "\n",
        "    return pd.DataFrame(data), num_classes\n",
        "\n",
        "def train_val_test_split(df: pd.DataFrame, train_size, val_size) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    vt_size = 1 - train_size\n",
        "    test_size = 1 - val_size / vt_size\n",
        "\n",
        "    train, val_test = train_test_split(df, test_size=vt_size, random_state=42)\n",
        "    val, test = train_test_split(val_test, test_size=test_size, random_state=42)\n",
        "    print(f'Training samples: {len(train)}, Validation samples: {len(val)}, Test samples: {len(test)}')\n",
        "    return train, val, test\n",
        "\n",
        "labels_df, num_classes = encode_labels()\n",
        "train_df, val_df, test_df = train_val_test_split(labels_df, .7, .2)"
      ],
      "metadata": {
        "id": "vqRAcC7sPEjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Classes"
      ],
      "metadata": {
        "id": "1DRoEWXoR3bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MLRSNet Dataset"
      ],
      "metadata": {
        "id": "X6TqT9ino4Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLRSNetDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.image_paths = df['image_path'].tolist()\n",
        "        self.multi_labels = np.stack(df['multi_labels'].values)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            image = Image.new('RGB', (224, 224))\n",
        "        multi_label = torch.from_numpy(self.multi_labels[idx])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, multi_label\n"
      ],
      "metadata": {
        "id": "KodlSDQWR1wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset Statistics (*needed for SimCLR transforms*)"
      ],
      "metadata": {
        "id": "txCainC5jrU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mean_std(loader, agg_batch_stats=False):\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    m = 0\n",
        "\n",
        "    for images, _ in loader:\n",
        "        images = images.to('cpu')\n",
        "        n = images.size(0)\n",
        "        images = images.view(n, images.size(1), -1)  # (B, C, H*W)\n",
        "\n",
        "        if agg_batch_stats:\n",
        "            mean += images.mean(2).sum(0).detach().clone()\n",
        "            std += images.std(2).sum(0).detach().clone()\n",
        "\n",
        "        else:\n",
        "            mean_m = mean.detach().clone()\n",
        "            mean_n = images.mean(2).sum(0)\n",
        "            mean = m*mean_m/(m+n) + n*mean_n/(m+n)\n",
        "\n",
        "            var_m = std.detach().clone() ** 2\n",
        "            var_n = images.var(2).sum(0)\n",
        "            var = m*var_m/(m+n) + n*var_n/(m+n) + m*n*(mean_m-mean_n)**2/(m+n)**2\n",
        "            std = torch.sqrt(var)\n",
        "\n",
        "        m += n\n",
        "\n",
        "    if agg_batch_stats:\n",
        "        mu /= m\n",
        "        std /= m\n",
        "\n",
        "    return mean.numpy(), std.numpy()\n",
        "\n",
        "\n",
        "compute_stats_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "stats_dataset = MLRSNetDataset(train_df, transform=compute_stats_transform)\n",
        "stats_loader = DataLoader(\n",
        "    stats_dataset,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    num_workers=8,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "train_mean, train_std = compute_mean_std(stats_loader)\n",
        "del stats_dataset, stats_loader\n",
        "print(f'Dataset Mean: {train_mean}')\n",
        "print(f'Dataset Std: {train_std}')\n",
        "\n",
        "simclr_pretrain_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=224, ratio=(1,1), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomApply([\n",
        "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.1) # brightness, contrast, saturation, hue\n",
        "    ], p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
        "])"
      ],
      "metadata": {
        "id": "jsfIEv8KXLcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SimCLR Pre-Training Dataset"
      ],
      "metadata": {
        "id": "y6XBcw71kS2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLRDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.image_paths = df['image_path'].tolist()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            view1 = self.transform(image)\n",
        "            view2 = self.transform(image)\n",
        "        else:\n",
        "            view1 = view2 = transforms.ToTensor()(image)\n",
        "\n",
        "        return view1, view2"
      ],
      "metadata": {
        "id": "ztratnVtkSfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Pre-Training"
      ],
      "metadata": {
        "id": "8LJDg3ZqswOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Modules"
      ],
      "metadata": {
        "id": "lZL3JvX9rYJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimCLR"
      ],
      "metadata": {
        "id": "O8rVEIMpvoCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder, projection_dim=128):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.encoder.fc = nn.Identity()  # Remove the original fully connected layer\n",
        "\n",
        "        # Projection head\n",
        "        self.projection_head = nn.Sequential(\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)  # [batch_size, 2048, 1, 1]\n",
        "        h = torch.flatten(h, start_dim=1)  # [batch_size, 2048]\n",
        "        z = self.projection_head(h)  # [batch_size, projection_dim]\n",
        "        return h, z\n",
        "\n",
        "\n",
        "class NTXentLoss(nn.Module):\n",
        "    def __init__(self, batch_size, temperature=0.5, device='cuda'):\n",
        "        super(NTXentLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "        self.device = device\n",
        "        self.mask = self._get_correlated_mask().type(torch.bool)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "    def _get_correlated_mask(self):\n",
        "        N = 2 * self.batch_size\n",
        "        mask = torch.ones((N, N), dtype=torch.float32)\n",
        "        mask = mask.fill_diagonal_(0)\n",
        "        for i in range(self.batch_size):\n",
        "            mask[i, self.batch_size + i] = 0\n",
        "            mask[self.batch_size + i, i] = 0\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    def forward(self, z_i, z_j):\n",
        "        N = 2 * self.batch_size\n",
        "        z = torch.cat((z_i, z_j), dim=0)  # [2N, projection_dim]\n",
        "\n",
        "        # Compute similarity matrix\n",
        "        sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=2)  # [2N, 2N]\n",
        "\n",
        "        sim = sim / self.temperature\n",
        "\n",
        "        # Exclude self-comparisons and positive pairs\n",
        "        sim_i_j = torch.diag(sim, self.batch_size)\n",
        "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
        "\n",
        "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0)  # [2N]\n",
        "        negative_samples = sim[self.mask].view(N, -1)  # [2N, 2N-2]\n",
        "\n",
        "        labels = torch.zeros(N).to(self.device).long()  # Positive samples are at index 0\n",
        "        logits = torch.cat((positive_samples.unsqueeze(1), negative_samples), dim=1)  # [2N, 2N-1]\n",
        "\n",
        "        loss = self.criterion(logits, labels)\n",
        "        loss /= N\n",
        "        return loss"
      ],
      "metadata": {
        "id": "WPcCp3IJppT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Training Routines"
      ],
      "metadata": {
        "id": "78Z7l79AwI5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Encoder (no pre-training)"
      ],
      "metadata": {
        "id": "X7HqYK-Z389-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_encoder = models.resnet50(weights='IMAGENET1K_V2')\n",
        "base_encoder.to(device)\n",
        "base_encoder_name = 'resnet50'\n",
        "\n",
        "base_encoder.fc = nn.Identity()"
      ],
      "metadata": {
        "id": "VW9OCoya4EYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimCLR"
      ],
      "metadata": {
        "id": "ZdwsKYs1xNYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAIN_EPOCHS_SIMCLR = 10\n",
        "PRETRAIN_LR_SIMCLR = 3e-4\n",
        "PRETRAIN_BATCH_SIZE_SIMCLR = 128\n",
        "PRETRAIN_TEMP_SIMCLR = 0.5\n",
        "\n",
        "model_simclr = SimCLR(copy.deepcopy(base_encoder)).to(device)\n",
        "\n",
        "dataset_simclr_pretrain = SimCLRDataset(train_df, transform=simclr_pretrain_transform)\n",
        "loader_simclr_pretrain = DataLoader(\n",
        "    dataset_simclr_pretrain,\n",
        "    batch_size=PRETRAIN_BATCH_SIZE_SIMCLR,\n",
        "    shuffle=True,\n",
        "    num_workers=8,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "print('SimCLR dataset and loader initialized.')\n",
        "\n",
        "opt_simclr = optim.Adam(model_simclr.parameters(), lr=PRETRAIN_LR_SIMCLR)\n",
        "criterion_simclr = NTXentLoss(batch_size=PRETRAIN_BATCH_SIZE_SIMCLR, temperature=PRETRAIN_TEMP_SIMCLR, device=device)\n",
        "\n",
        "model_simclr.train()\n",
        "for epoch in range(1, PRETRAIN_EPOCHS_SIMCLR + 1):\n",
        "    total_loss = 0.0\n",
        "    for step, (view1, view2) in enumerate(loader_simclr_pretrain):\n",
        "        view1 = view1.to(device, non_blocking=True)\n",
        "        view2 = view2.to(device, non_blocking=True)\n",
        "\n",
        "        opt_simclr.zero_grad()\n",
        "\n",
        "        h1, z1 = model_simclr(view1)\n",
        "        h2, z2 = model_simclr(view2)\n",
        "\n",
        "        loss = criterion_simclr(z1, z2)\n",
        "        loss.backward()\n",
        "        opt_simclr.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader_simclr_pretrain)\n",
        "    print(f'SimCLR Epoch [{epoch}/{PRETRAIN_EPOCHS_SIMCLR}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # save checkpoints\n",
        "    checkpoint_path = f'/content/simclr/{base_encoder_name}/pretrain/epoch-{epoch}_loss-{avg_loss:.4f}.pth'\n",
        "    os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "    torch.save(model_simclr.state_dict(), checkpoint_path)\n",
        "    print(f'Checkpoint saved at {checkpoint_path}')"
      ],
      "metadata": {
        "id": "OygBlGpuxMsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Evaluation"
      ],
      "metadata": {
        "id": "omIc6ivb6MK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Label Linear Probe"
      ],
      "metadata": {
        "id": "D32hsJtn6hmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiLabelLinearProbe(nn.Module):\n",
        "    def __init__(self, encoder_output_dim, num_classes):\n",
        "        super(MultiLabelLinearProbe, self).__init__()\n",
        "        self.linear = nn.Linear(encoder_output_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yK1CPZlB6QCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Routine"
      ],
      "metadata": {
        "id": "ufRMkaSd8wDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-3\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "def linear_eval_trainval(encoder, probe, model_name, encoder_name, num_epochs, criterion, optimizer, train_set, train_load, val_set, val_load) -> dict:\n",
        "    metrics = {\n",
        "        'epoch': list(range(1, num_epochs+1)),\n",
        "        'train_loss': list(),\n",
        "        'val_loss': list(),\n",
        "        'val_mAP': list()\n",
        "    }\n",
        "\n",
        "    for param in encoder.parameters():\n",
        "        param.requires_grad = False\n",
        "    print('Encoder weights frozen.')\n",
        "\n",
        "    # train linear probe\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        probe.train()\n",
        "        running_loss_train = 0.0\n",
        "\n",
        "        for images, multi_labels in train_load:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            multi_labels = multi_labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embeddings = encoder(images)\n",
        "\n",
        "            outputs = probe(embeddings)\n",
        "            loss = criterion(outputs, multi_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss_train += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss_train = running_loss_train / len(train_set)\n",
        "        print(f'Classification Training Epoch [{epoch}/{num_epochs}], Loss: {epoch_loss_train:.4f}')\n",
        "        metrics['train_loss'].append(epoch_loss_train)\n",
        "\n",
        "        # validation\n",
        "        probe.eval()\n",
        "        running_loss_val = 0.0\n",
        "        all_targets = []\n",
        "        all_outputs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, multi_labels in val_load:\n",
        "                images = images.to(device, non_blocking=True)\n",
        "                multi_labels = multi_labels.to(device, non_blocking=True)\n",
        "\n",
        "                embeddings = encoder(images)\n",
        "                outputs = probe(embeddings)\n",
        "\n",
        "                loss = criterion(outputs, multi_labels)\n",
        "                running_loss_val += loss.item() * images.size(0)\n",
        "\n",
        "                all_targets.append(multi_labels.cpu().numpy())\n",
        "                all_outputs.append(outputs.cpu().numpy())\n",
        "\n",
        "        epoch_loss_val = running_loss_val / len(val_set)\n",
        "        print(f'Validation Loss: {epoch_loss_val:.4f}')\n",
        "        metrics['val_loss'].append(epoch_loss_val)\n",
        "\n",
        "        # compute mAP\n",
        "        all_targets = np.vstack(all_targets)\n",
        "        all_outputs = np.vstack(all_outputs)\n",
        "        all_outputs = 1 / (1 + np.exp(-all_outputs))  # sigmoid activation\n",
        "\n",
        "        average_precisions = []\n",
        "        for i in range(num_classes):\n",
        "            try:\n",
        "                ap = average_precision_score(all_targets[:, i], all_outputs[:, i])\n",
        "            except ValueError:\n",
        "                ap = 0.0  # edge case: no positive labels\n",
        "            average_precisions.append(ap)\n",
        "\n",
        "        mAP_val = np.mean(average_precisions)\n",
        "        print(f'mAP (Multi-Label): {mAP_val:.4f}')\n",
        "        metrics['val_mAP'].append(mAP_val)\n",
        "\n",
        "        # save checkpoints\n",
        "        checkpoint_path = f'/content/{model_name}/{encoder_name}/eval/epoch-{epoch}_loss-{epoch_loss_val:.4f}_mAP-{mAP_val:.4f}.pth'\n",
        "        os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "        torch.save(probe.state_dict(), checkpoint_path)\n",
        "        print(f'Checkpoint saved at {checkpoint_path}')\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def get_min_loss_pretrained(model_name, encoder_name):\n",
        "    min_loss = float('inf')\n",
        "    min_loss_path = None\n",
        "    for filename in os.listdir(f'/content/{model_name}/{encoder_name}/pretrain/'):\n",
        "        if filename.endswith('.pth'):\n",
        "            loss_value = float(filename.split('_')[1].split('-')[1].split('.')[0])\n",
        "            if loss_value < min_loss:\n",
        "                min_loss = loss_value\n",
        "                min_loss_path = os.path.join(f'/content/{model_name}/{encoder_name}/pretrain/', filename)\n",
        "    return min_loss_path\n",
        "\n",
        "\n",
        "def linear_eval_test(encoder, probe, test_set, test_load) -> float:\n",
        "    probe.eval()\n",
        "    running_loss_test = 0.0\n",
        "    all_targets = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, multi_labels in test_load:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            multi_labels = multi_labels.to(device, non_blocking=True)\n",
        "\n",
        "            embeddings = encoder(images)\n",
        "            outputs = probe(embeddings)\n",
        "\n",
        "            all_targets.append(multi_labels.cpu().numpy())\n",
        "            all_outputs.append(outputs.cpu().numpy())\n",
        "\n",
        "        all_targets = np.vstack(all_targets)\n",
        "        all_outputs = np.vstack(all_outputs)\n",
        "        all_outputs = 1 / (1 + np.exp(-all_outputs))  # sigmoid activation\n",
        "\n",
        "        average_precisions = []\n",
        "        for i in range(num_classes):\n",
        "            try:\n",
        "                ap = average_precision_score(all_targets[:, i], all_outputs[:, i])\n",
        "            except ValueError:\n",
        "                ap = 0.0  # edge case: no positive labels\n",
        "            average_precisions.append(ap)\n",
        "\n",
        "        mAP_val = np.mean(average_precisions)\n",
        "        print(f'mAP (Multi-Label): {mAP_val:.4f}')\n",
        "        return mAP_val\n",
        "\n",
        "\n",
        "def get_max_mAP_eval(model_name, encoder_name):\n",
        "    max_mAP = float('-inf')\n",
        "    max_mAP_path = None\n",
        "    for filename in os.listdir(f'/content/{model_name}/{encoder_name}/eval/'):\n",
        "        if filename.endswith('.pth'):\n",
        "            mAP_value = float(filename.split('_')[2].split('-')[1].split('.')[0])\n",
        "            if mAP_value > max_mAP:\n",
        "                max_mAP = mAP_value\n",
        "                max_mAP_path = os.path.join(f'/content/{model_name}/{encoder_name}/eval/', filename)\n",
        "    return max_mAP_path\n",
        "\n",
        "\n",
        "def linear_eval(model_name, encoder_name, train_set, train_load, val_set, val_load, test_set, test_load):\n",
        "    probe = MultiLabelLinearProbe(\n",
        "        encoder_output_dim=2048,\n",
        "        num_classes=num_classes\n",
        "    ).to(device)\n",
        "\n",
        "    if model_name == 'baseline':\n",
        "        encoder = base_encoder.to(device)\n",
        "    elif model_name == 'simclr':\n",
        "        best_loss_path = get_min_loss_pretrained(model_name, encoder_name)\n",
        "        model_simclr.load_state_dict(torch.load(best_loss_path, map_location=device))\n",
        "        encoder = model_simclr.encoder.to(device)\n",
        "    else:\n",
        "        raise ValueError('Invalid model name.')\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(probe.parameters(), lr=LEARNING_RATE)\n",
        "    print('Supervised loss function and optimizer initialized.')\n",
        "\n",
        "    metrics = linear_eval_trainval(\n",
        "        encoder=encoder,\n",
        "        probe=probe,\n",
        "        model_name=model_name,\n",
        "        encoder_name=encoder_name,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        train_set=train_set,\n",
        "        train_load=train_load,\n",
        "        val_set=val_set,\n",
        "        val_load=val_load\n",
        "    )\n",
        "\n",
        "    max_mAP_path = get_max_mAP_eval(model_name, encoder_name)\n",
        "    probe.load_state_dict(torch.load(max_mAP_path, map_location=device))\n",
        "\n",
        "    mAP = linear_eval_test(\n",
        "        encoder=encoder,\n",
        "        probe=probe,\n",
        "        test_set=test_set,\n",
        "        test_load=test_load\n",
        "    )\n",
        "\n",
        "    return metrics, mAP\n",
        "\n",
        "\n",
        "def visualize(full_metrics, test_mAP):\n",
        "    # side-by-side comparison of training losses across models\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    for model_name, metrics in full_metrics.items():\n",
        "        plt.plot(metrics['epoch'], metrics['train_loss'])\n",
        "    fig.suptitle('Training Loss Comparison')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(full_metrics.keys())\n",
        "    os.makedirs('/content/output/', exist_ok=True)\n",
        "    plt.savefig('/content/output/training_loss_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "    # side-by-side comparison of validation losses across models\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    for model_name, metrics in full_metrics.items():\n",
        "        plt.plot(metrics['epoch'], metrics['val_loss'])\n",
        "    fig.suptitle('Validation Loss Comparison')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(full_metrics.keys())\n",
        "    plt.savefig('/content/output/validation_loss_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "    # side-by-side comparison of validation mAP across models\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    for model_name, metrics in full_metrics.items():\n",
        "        plt.plot(metrics['epoch'], metrics['val_mAP'])\n",
        "    fig.suptitle('Validation mAP Comparison')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.legend(full_metrics.keys())\n",
        "    plt.savefig('/content/output/validation_mAP_comparison.png')\n",
        "\n",
        "    # side-by-side comparison of test mAP across models\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    for model_name, mAP in test_mAP.items():\n",
        "        plt.bar(model_name, mAP)\n",
        "    fig.suptitle('Test mAP Comparison')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel('mAP')\n",
        "    plt.savefig('/content/output/test_mAP_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def main():\n",
        "    eval_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
        "    ])\n",
        "    train_set = MLRSNetDataset(df=train_df, transform=eval_transform)\n",
        "    train_load = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=8,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    val_set = MLRSNetDataset(df=val_df, transform=eval_transform)\n",
        "    val_load = DataLoader(\n",
        "        val_set,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=8,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    test_set = MLRSNetDataset(df=test_df, transform=eval_transform)\n",
        "    test_load = DataLoader(\n",
        "        test_set,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=8,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    full_metrics = {}\n",
        "    test_mAP = {}\n",
        "    for model_name in ['baseline', 'mae']:\n",
        "        metrics, mAP = linear_eval(\n",
        "            model_name, base_encoder_name,\n",
        "            train_set, train_load,\n",
        "            val_set, val_load,\n",
        "            test_set, test_load\n",
        "        )\n",
        "        full_metrics[model_name] = metrics\n",
        "        test_mAP[model_name] = mAP\n",
        "\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "GxN6RXDMbmHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Results to Drive"
      ],
      "metadata": {
        "id": "I8kzJospySrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zip_folders(output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # TODO: ADD MAE\n",
        "        for folder_name in ['output', 'simclr', 'baseline']:\n",
        "            folder_path = os.path.join('/content', folder_name)\n",
        "            for root, _, files in os.walk(folder_path):\n",
        "                for file in files:\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    zipf.write(file_path, os.path.relpath(file_path, '/content'))\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "zip_folders(f'/content/drive/MyDrive/CS2952Q-FP/results/results_{timestamp}.zip')"
      ],
      "metadata": {
        "id": "LyAvAgRp0ClP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}